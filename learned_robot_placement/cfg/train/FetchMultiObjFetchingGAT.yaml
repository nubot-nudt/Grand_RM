name: FetchMultiObjFetchingGAT

params:
  seed: ${...seed}

  algo:
    name: GAT # Has to match class name if using mushroom RL library

  load_checkpoint: ${if:${...checkpoint},True,False} # flag which sets whether to load the checkpoint
#  load_path: ${...checkpoint} # path to the checkpoint to load


  config:
    name: ${resolve_default:${....train.name},${....experiment}}
    device: ${....rl_device}
    device_name: ${....rl_device}
    num_actors: ${....task.env.numEnvs}
    log_checkpoints: True
    
    # network:
    n_features: 256 # Default is two layer FCN
    lr_actor_net: 0.0003  # 降低学习率
    lr_critic_net: 0.0003  # 降低学习率
    batch_size: 256
    # algo:
    initial_replay_size: 256
    max_replay_size: 75000
    warmup_transitions: 1024
    tau: 0.005
    lr_alpha: 0.0001
    temperature: 1.0 # For the softmax of gumbel
    # target_entropy: # automatic as per action space
    log_std_min: -3 # Clip the agent's policy log std to avoid very narrow gaussian policies
    # runner:
    n_epochs: 520
    n_steps: 800 # training
    n_steps_test: 120
    # use_graph or not
    use_graph: True
    # boosting:
#    prior_agents: [logs/FetchReaching/FetchReachingBHyRL/2024-04-15-22-30-59/2024-04-15-22-30-59/agent-500.msh] # list of prior agent paths
#    use_kl_on_pi: True
#    kl_on_pi_alpha: 1e-3
    prior_agents: [] # list of prior agent paths
    use_kl_on_pi: False
    kl_on_pi_alpha: 1e-3